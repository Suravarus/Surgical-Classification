{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surgical Classification: Complication prediction\n",
    "\n",
    "\n",
    "We are given a dataset which has 25 columns, and 14636 rows. The first row is a header, and the last column is the target. will be using Tablesaw to easily create a table out of the CSV dataset. The goal is to learn from this data, and be able to make a prediction based on pre-existing conditions, the chance of a patient having a complication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Tablesaw for graphing\n",
    "\n",
    "\n",
    "\n",
    "We now have the header in it's own Array, and all of the content in a 2d array. We are able to examine any of the data we want, being able to match each column with the proper header. Eventually we will need to randomize the order of the rows, but for now it's not important.\n",
    "\n",
    "The next two cells implement Tablesaw graph into the notebook.\n",
    "I did not do this code myself, I found somebody who gave this code on stack overflow. The post can be found here: https://stackoverflow.com/questions/54654434/how-to-embed-tablesaw-graph-in-jupyter-notebook-with-ijava-kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%loadFromPOM\n",
    "<dependency>\n",
    "    <groupId>tech.tablesaw</groupId>\n",
    "    <artifactId>tablesaw-jsplot</artifactId>\n",
    "    <version>0.38.0</version>\n",
    "</dependency>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io.github.spencerpark.ijava.IJava;\n",
    "\n",
    "IJava.getKernelInstance().getRenderer()\n",
    "    .createRegistration(tech.tablesaw.plotly.components.Figure.class)\n",
    "    .preferring(io.github.spencerpark.jupyter.kernel.display.mime.MIMEType.TEXT_HTML)\n",
    "    .register((figure, ctx) -> {\n",
    "        ctx.renderIfRequested(io.github.spencerpark.jupyter.kernel.display.mime.MIMEType.TEXT_HTML, () -> {\n",
    "            String id = UUID.randomUUID().toString().replace(\"-\", \"\");\n",
    "\n",
    "            figure.asJavascript(id);\n",
    "            Map<String, Object> context = figure.getContext();\n",
    "\n",
    "            StringBuilder html = new StringBuilder();\n",
    "            html.append(\"<div id=\\\"\").append(id).append(\"\\\"></div>\\n\");\n",
    "            html.append(\"<script>require(['https://cdn.plot.ly/plotly-1.44.4.min.js'], Plotly => {\\n\");\n",
    "            html.append(\"var target_\").append(id).append(\" = document.getElementById('\").append(id).append(\"');\\n\");\n",
    "            html.append(context.get(\"figure\")).append('\\n');\n",
    "            html.append(context.get(\"plotFunction\")).append('\\n');\n",
    "            html.append(\"})</script>\\n\");\n",
    "            return html.toString();\n",
    "        });\n",
    "    });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n"
     ]
    }
   ],
   "source": [
    "import java.io.BufferedReader;\n",
    "import java.io.FileReader;\n",
    "import java.io.IOException;\n",
    "import java.io.BufferedReader;\n",
    "import java.lang.*;\n",
    "import tech.tablesaw.api.*;\n",
    "import tech.tablesaw.plotly.api.*;\n",
    "import tech.tablesaw.plotly.components.*;\n",
    "\n",
    "\n",
    "String csv = \"/Users/surav/notebook/Java ML Project/Surgical-deepnet.csv\"; //CSV file directory\n",
    "Table Data = Table.read().csv(csv); //Create a table of the CSV\n",
    "\n",
    "//An error may pop up, but as far as I can tell everything still works even when it does.\n",
    "//Running the cells 1 at a time makes the error go away for me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Data\n",
    "\n",
    "\n",
    "Taking a closer look at the data we're working with will help us when graphing it. Right now we want to know exactly how much data we have, and what types of data our attributes are being stored as. Remember, the target is in the last column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14635 rows X 25 cols"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.shape(); //Show number of rows and columns in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       Structure of Surgical-deepnet.csv        \r\n",
       " Index  |     Column Name      |  Column Type  |\r\n",
       "------------------------------------------------\r\n",
       "     0  |                 bmi  |       DOUBLE  |\r\n",
       "     1  |                 Age  |       DOUBLE  |\r\n",
       "     2  |          asa_status  |      INTEGER  |\r\n",
       "     3  |     baseline_cancer  |      INTEGER  |\r\n",
       "     4  |   baseline_charlson  |      INTEGER  |\r\n",
       "     5  |        baseline_cvd  |      INTEGER  |\r\n",
       "     6  |   baseline_dementia  |      INTEGER  |\r\n",
       "     7  |   baseline_diabetes  |      INTEGER  |\r\n",
       "     8  |  baseline_digestive  |      INTEGER  |\r\n",
       "     9  |   baseline_osteoart  |      INTEGER  |\r\n",
       "   ...  |                 ...  |          ...  |\r\n",
       "    15  |    complication_rsi  |       DOUBLE  |\r\n",
       "    16  |                 dow  |      INTEGER  |\r\n",
       "    17  |              gender  |      INTEGER  |\r\n",
       "    18  |                hour  |       DOUBLE  |\r\n",
       "    19  |               month  |      INTEGER  |\r\n",
       "    20  |           moonphase  |      INTEGER  |\r\n",
       "    21  |              mort30  |      INTEGER  |\r\n",
       "    22  |       mortality_rsi  |       DOUBLE  |\r\n",
       "    23  |                race  |      INTEGER  |\r\n",
       "    24  |        complication  |      INTEGER  |"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.structure(); /*Show info of the dataset, column names and types.\n",
    "10           baseline_psych                     INTEGER\n",
    "11           baseline_pulmonary                 INTEGER\n",
    "12           ahrq_ccs                           INTEGER\n",
    "13           ccsComplicationRate                DOUBLE\n",
    "14           ccsMort30Rate                      DOUBLE\n",
    "The above columns do not show up in the table below.\n",
    "*/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complication graph\n",
    "\n",
    "\n",
    "When graphing, we'll look at percentages and averages instead of actual numbers. It's more relevant to us if 70% of patients with a certain condition experience a complication, than knowing that 150 patients with the condition experience a complication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Easily changable graphs\n",
    "\n",
    "\n",
    "\n",
    "Below is an easy way to check the complication rate for any other integer in the dataset. Changing the condition to any name of an integer column in the table allows us to examine the percentage of each category which experiences a complication in surgery. This can help us determine which columns are good to prune away, specifically if the complication rate is extremely close for every number that appears. We're able to get a very good understanding of the integers in this dataset with these graphs.\n",
    "\n",
    "Looking at doubles is a bit trickier. I couldn't find a way to give a more accurate representation of the data, so for doubles we are looking at the average value for the column when the complication is 1 and when it is 0. This does mean that 0 will not have an impact on the graph, so if it is a common digit in the column, it risks being overlooked entirely.\n",
    "\n",
    "Before looking at graphs, lets change bmi, Age and Hour to integers. We will lose some significance from bmi, but most of the impact comes from the integer number even when it's a double."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       Structure of Surgical-deepnet.csv        \r\n",
       " Index  |     Column Name      |  Column Type  |\r\n",
       "------------------------------------------------\r\n",
       "     0  |                 bmi  |      INTEGER  |\r\n",
       "     1  |                 Age  |      INTEGER  |\r\n",
       "     2  |          asa_status  |      INTEGER  |\r\n",
       "     3  |     baseline_cancer  |      INTEGER  |\r\n",
       "     4  |   baseline_charlson  |      INTEGER  |\r\n",
       "     5  |        baseline_cvd  |      INTEGER  |\r\n",
       "     6  |   baseline_dementia  |      INTEGER  |\r\n",
       "     7  |   baseline_diabetes  |      INTEGER  |\r\n",
       "     8  |  baseline_digestive  |      INTEGER  |\r\n",
       "     9  |   baseline_osteoart  |      INTEGER  |\r\n",
       "   ...  |                 ...  |          ...  |\r\n",
       "    15  |    complication_rsi  |       DOUBLE  |\r\n",
       "    16  |                 dow  |      INTEGER  |\r\n",
       "    17  |              gender  |      INTEGER  |\r\n",
       "    18  |                hour  |      INTEGER  |\r\n",
       "    19  |               month  |      INTEGER  |\r\n",
       "    20  |           moonphase  |      INTEGER  |\r\n",
       "    21  |              mort30  |      INTEGER  |\r\n",
       "    22  |       mortality_rsi  |       DOUBLE  |\r\n",
       "    23  |                race  |      INTEGER  |\r\n",
       "    24  |        complication  |      INTEGER  |"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import static tech.tablesaw.aggregate.AggregateFunctions.sum;\n",
    "import static tech.tablesaw.aggregate.AggregateFunctions.mean;\n",
    "import tech.tablesaw.api.IntColumn;\n",
    "import tech.tablesaw.api.DoubleColumn;\n",
    "\n",
    "//Changing some double columns to int columns\n",
    "\n",
    "IntColumn temp1 = Data.doubleColumn(\"bmi\").asIntColumn(); //bmi column as an int column\n",
    "IntColumn temp2 = Data.doubleColumn(\"Age\").asIntColumn(); //Age column as an int column\n",
    "IntColumn temp3 = Data.doubleColumn(\"Hour\").asIntColumn(); //Hour column as an int column\n",
    "\n",
    "Data.removeColumns(\"bmi\", \"Age\", \"Hour\"); //Remove bmi Age and Hour from the table\n",
    "Data.insertColumn(0, temp1); //insert temp1 column to the table in index 0\n",
    "Data.insertColumn(1, temp2); //insert temp2 column to the table in index 1\n",
    "Data.insertColumn(18, temp3); //insert temp3 column to the table in index 18\n",
    "//The structure should maintain it's original shape, but the Age and Hour columns are now Integer types.\n",
    "\n",
    "Data.structure();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplication in the Dataset\n",
    "\n",
    "I noticed an error in the data. There are a lot of rows with identical information. So before looking at the data in graphs, we need to clean this up. It's extremely unlikely to have the same exact conditions multiple times with this many attributes, so we'll be removing all duplicate rows. This risks removing actual data, but there were well over 100 duplicate rows that I found by hand, so it should make our result better. The result of this error can be seen in the following graph, where people aged 90 are very unlikely to have a complication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"2a8372057c4b476792ba5dae7d2d65d8\"></div>\n",
       "<script>require(['https://cdn.plot.ly/plotly-1.44.4.min.js'], Plotly => {\n",
       "var target_2a8372057c4b476792ba5dae7d2d65d8 = document.getElementById('2a8372057c4b476792ba5dae7d2d65d8');\n",
       "var layout = {\n",
       "    title: '% complication by Age',\n",
       "    height: 700,\n",
       "    width: 900,\n",
       "\n",
       "\n",
       "};\n",
       "\r\n",
       "var trace0 =\n",
       "{\n",
       "x: [\"59\",\"58\",\"57\",\"56\",\"55\",\"54\",\"41\",\"40\",\"39\",\"38\",\"37\",\"36\",\"35\",\"34\",\"33\",\"32\",\"75\",\"74\",\"73\",\"72\",\"71\",\"70\",\"90\",\"69\",\"68\",\"67\",\"66\",\"65\",\"64\",\"63\",\"62\",\"61\",\"60\",\"53\",\"52\",\"51\",\"50\",\"49\",\"48\",\"47\",\"46\",\"45\",\"44\",\"43\",\"42\",\"31\",\"30\",\"29\",\"28\",\"27\",\"89\",\"88\",\"87\",\"86\",\"85\",\"84\",\"83\",\"82\",\"81\",\"80\",\"79\",\"78\",\"77\",\"76\",\"26\",\"25\",\"24\",\"23\",\"22\",\"21\",\"20\",\"19\",\"18\",\"17\",\"16\",\"15\",\"14\",\"12\",\"8\",\"6\"],\n",
       "y: [0.4135338345864657, 0.18376068376068488, 0.12747875354107766, 0.13452914798206142, 0.1152737752161381, 0.1995192307692299, 0.2708333333333337, 0.10682492581602335, 0.11111111111111142, 0.09689922480620197, 0.10780669144981438, 0.1021276595744685, 0.11764705882352976, 0.09944751381215439, 0.10526315789473702, 0.1614906832298137, 0.7291666666666666, 0.1538461538461543, 0.14849187935034874, 0.1680161943319844, 0.1685185185185182, 0.26058631921824094, 0.006842285323297866, 0.8484848484848487, 0.7924528301886791, 0.746666666666667, 0.7214285714285713, 0.7000000000000004, 0.664285714285714, 0.5705521472392636, 0.5149999999999996, 0.46938775510204095, 0.49107142857142805, 0.3395348837209306, 0.36585365853658464, 0.4277108433734939, 0.46625766871165714, 0.3777777777777776, 0.47499999999999926, 0.5, 0.4954954954954949, 0.4848484848484852, 0.4399999999999997, 0.43809523809523854, 0.5595238095238092, 0.8571428571428571, 0.85, 0.9310344827586208, 0.8823529411764706, 0.9411764705882353, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
       "orientation: 'v',\n",
       "xaxis: 'x',\n",
       "yaxis: 'y',\n",
       "type: 'bar',\n",
       "name: '',\n",
       "};\r\n",
       "\r\n",
       "\n",
       "var data = [ trace0];\r\n",
       "Plotly.newPlot(target_2a8372057c4b476792ba5dae7d2d65d8, data, layout);\n",
       "})</script>\n"
      ],
      "text/plain": [
       "tech.tablesaw.plotly.components.Figure@dd723a5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "11733 rows X 25 cols"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "String condition1 = \"Age\"; //using string as what we're testing against the complication data\n",
    "//The input string must point to an integer type column.\n",
    "String target = \"complication\"; //this is what we're comparing against. by default is the target.\n",
    "\n",
    "Table Error = Data.summarize(target, mean).by(\"Age\"); //table of complication and condition\n",
    "\n",
    "Figure figure = VerticalBarPlot.create(\"% \" + target + \" by Age\", //plot title\n",
    "    Error,                  //table\n",
    "    \"Age\",                  //grouping column name\n",
    "    \"mean [\" + target + \"]\"); //numeric column name\n",
    "\n",
    "//removing duplicate rows\n",
    "Data = Data.dropDuplicateRows(); //sets the table to the table without duplicates\n",
    "\n",
    "\n",
    "//showing the graph from before the rows were duplicated\n",
    "display(figure);\n",
    "\n",
    "Data.shape();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"24d87ee4be034454a22cef91252f552c\"></div>\n",
       "<script>require(['https://cdn.plot.ly/plotly-1.44.4.min.js'], Plotly => {\n",
       "var target_24d87ee4be034454a22cef91252f552c = document.getElementById('24d87ee4be034454a22cef91252f552c');\n",
       "var layout = {\n",
       "    title: '% complication by Age',\n",
       "    height: 700,\n",
       "    width: 900,\n",
       "\n",
       "\n",
       "};\n",
       "\r\n",
       "var trace0 =\n",
       "{\n",
       "x: [\"57\",\"40\",\"55\",\"72\",\"90\",\"6\",\"12\",\"37\",\"56\",\"60\",\"68\",\"17\",\"30\",\"34\",\"35\",\"36\",\"47\",\"50\",\"58\",\"59\",\"75\",\"81\",\"19\",\"20\",\"25\",\"29\",\"31\",\"32\",\"33\",\"38\",\"51\",\"54\",\"61\",\"63\",\"65\",\"67\",\"71\",\"74\",\"82\",\"8\",\"21\",\"23\",\"27\",\"39\",\"41\",\"53\",\"70\",\"77\",\"78\",\"79\",\"14\",\"15\",\"26\",\"28\",\"43\",\"44\",\"48\",\"49\",\"52\",\"62\",\"66\",\"84\",\"86\",\"87\",\"24\",\"42\",\"46\",\"69\",\"73\",\"76\",\"80\",\"83\",\"16\",\"18\",\"45\",\"64\",\"85\",\"88\",\"89\",\"22\"],\n",
       "y: [0.12747875354107643, 0.10682492581602372, 0.11527377521613834, 0.1680161943319837, 0.9523809523809523, 1.0, 1.0, 0.10780669144981425, 0.13452914798206284, 0.4910714285714285, 0.7924528301886791, 1.0, 0.85, 0.09944751381215465, 0.1176470588235294, 0.102127659574468, 0.5, 0.4662576687116571, 0.1837606837606837, 0.4135338345864657, 0.7291666666666666, 1.0, 1.0, 1.0, 1.0, 0.9310344827586208, 0.8571428571428571, 0.1614906832298136, 0.10526315789473689, 0.09689922480620156, 0.4277108433734946, 0.1995192307692313, 0.46938775510204095, 0.5705521472392634, 0.7000000000000004, 0.746666666666667, 0.1685185185185185, 0.1538461538461538, 1.0, 1.0, 1.0, 1.0, 0.9411764705882353, 0.11111111111111108, 0.2708333333333333, 0.3395348837209306, 0.26058631921824094, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8823529411764706, 0.43809523809523826, 0.43999999999999995, 0.4749999999999993, 0.3777777777777778, 0.3658536585365847, 0.5149999999999996, 0.7214285714285713, 1.0, 1.0, 1.0, 1.0, 0.5595238095238092, 0.49549549549549515, 0.8484848484848486, 0.14849187935034802, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4848484848484852, 0.664285714285714, 1.0, 1.0, 1.0, 1.0],\n",
       "orientation: 'v',\n",
       "xaxis: 'x',\n",
       "yaxis: 'y',\n",
       "type: 'bar',\n",
       "name: '',\n",
       "};\r\n",
       "\r\n",
       "\n",
       "var data = [ trace0];\r\n",
       "Plotly.newPlot(target_24d87ee4be034454a22cef91252f552c, data, layout);\n",
       "})</script>\n"
      ],
      "text/plain": [
       "tech.tablesaw.plotly.components.Figure@97da47c"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "               Surgical-deepnet.csv summary                \r\n",
       " Summary   |         Age          |  Mean [complication]  |\r\n",
       "-----------------------------------------------------------\r\n",
       "    Count  |                  80  |                   80  |\r\n",
       "      sum  |                4030  |   51.385688043736565  |\r\n",
       "     Mean  |  50.374999999999986  |   0.6423211005467073  |\r\n",
       "      Min  |                   6  |  0.09689922480620156  |\r\n",
       "      Max  |                  90  |                    1  |\r\n",
       "    Range  |                  84  |   0.9031007751937985  |\r\n",
       " Variance  |    550.363924050633  |  0.12568702395083914  |\r\n",
       " Std. Dev  |   23.45983640289576  |  0.35452365781543993  |"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//This graph shows the data without the duplicates. nearly 3000 rows were removed.\n",
    "//The string \"condition\" can be changed to any integer column, and will display a graph and table.\n",
    "\n",
    "String condition1 = \"Age\"; //using string as what we're testing against the complication data\n",
    "//The input string must point to an integer type column.\n",
    "String target = \"complication\";//this is what we're comparing against. by default is the target.\n",
    "\n",
    "Table complications1 = Data.summarize(target, mean).by(condition1); //table of complication and condition\n",
    "\n",
    "Figure figure = VerticalBarPlot.create(\"% \" + target + \" by \" + condition1, //plot title\n",
    "    complications1,         //table\n",
    "    condition1,              //grouping column name\n",
    "    \"mean [\" + target + \"]\"); //numeric column name\n",
    "\n",
    "display(figure); //displays a graph of the table\n",
    "complications1.summary(); //gives information for the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"02b2bb94302947e4b9d44196d70f375b\"></div>\n",
       "<script>require(['https://cdn.plot.ly/plotly-1.44.4.min.js'], Plotly => {\n",
       "var target_02b2bb94302947e4b9d44196d70f375b = document.getElementById('02b2bb94302947e4b9d44196d70f375b');\n",
       "var layout = {\n",
       "    title: 'Average mortality_rsi of complication status',\n",
       "    height: 700,\n",
       "    width: 900,\n",
       "\n",
       "\n",
       "};\n",
       "\r\n",
       "var trace0 =\n",
       "{\n",
       "x: [\"0\",\"1\"],\n",
       "y: [-0.6627427576774825, -0.10442818428184356],\n",
       "orientation: 'v',\n",
       "xaxis: 'x',\n",
       "yaxis: 'y',\n",
       "type: 'bar',\n",
       "name: '',\n",
       "};\r\n",
       "\r\n",
       "\n",
       "var data = [ trace0];\r\n",
       "Plotly.newPlot(target_02b2bb94302947e4b9d44196d70f375b, data, layout);\n",
       "})</script>\n"
      ],
      "text/plain": [
       "tech.tablesaw.plotly.components.Figure@7f5b6a17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "                Surgical-deepnet.csv summary                \r\n",
       " Summary   |     complication     |  Mean [mortality_rsi]  |\r\n",
       "------------------------------------------------------------\r\n",
       "    Count  |                   2  |                     2  |\r\n",
       "      sum  |                   1  |    -0.767170941959326  |\r\n",
       "     Mean  |                 0.5  |    -0.383585470979663  |\r\n",
       "      Min  |                   0  |   -0.6627427576774825  |\r\n",
       "      Max  |                   1  |  -0.10442818428184356  |\r\n",
       "    Range  |                   1  |     0.558314573395639  |\r\n",
       " Variance  |                 0.5  |   0.15585758143297715  |\r\n",
       " Std. Dev  |  0.7071067811865476  |    0.3947880208833307  |"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "String condition2 = \"mortality_rsi\"; //using string as what we're testing against the complication data\n",
    "//The input string can point to a double type column.\n",
    "String target = \"complication\"; //this is what we're comparing against. by default is the target.\n",
    "\n",
    "Table complications2 = Data.summarize(condition2, mean).by(target); //table of condition2 and complication\n",
    "\n",
    "Figure figure = VerticalBarPlot.create(\"Average \" + condition2 + \" of \"+ target + \" status\", //plot title\n",
    "    complications2,                  //table\n",
    "    target,                          //grouping column name\n",
    "    \"mean [\" + condition2 + \"]\");    //numeric column name\n",
    "\n",
    "display(figure); //Display the graph of the table\n",
    "complications2.summary(); //Displays information for the table\n",
    "//complication column will always be the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Management\n",
    "\n",
    "\n",
    "\n",
    "To start off we want to look at integer attributes, where there are multiple values of the same attribute which have similar impact on the complication for a patient. We need to set a threshold, in this case we'll be using +/-2.5%, which is close enough to justify merging the different values. We will combine the values into the same integer if they are within the threshold, and then move on to the next attribute. \n",
    "\n",
    "After we've consolodated the data for the attributes, we need to again make minor modifications to the stored data. If there are only 2 integers remaining, we should change those to +1 and -1, regardless of what their values were before. If there are more than two numbers remaining we need to reexamine the attribute. If the numbers were sequential, we need to reorder them in accordance to how they were before (for example if the numbers were 1-10 but now are only 1, 2 and 6, they become 1, 2, 3). If they were not sequential and instead represent something which cannot be boiled down further, we may leave the values in their new state.\n",
    "\n",
    "If there are any integer attributes with only 1 digit after this process, they need to be removed from the dataset, and be declared useless for determining the complication for a patient. Similarly we can prune double attributes if the average for the complication status is within the same threshold of +/-2.5%.\n",
    "\n",
    "One important thing to remember is that if we wanted to find predictions for new data, any modifications we make to the dataset before training will need to be done to that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bmi; Integer\n",
      "Age; Integer\n",
      "asa_status; Integer\n",
      "baseline_cancer; Integer\n",
      "baseline_charlson; Integer\n",
      "baseline_cvd; Integer\n",
      "baseline_dementia; Integer\n",
      "baseline_diabetes; Integer\n",
      "baseline_digestive; Integer\n",
      "baseline_osteoart; Integer\n",
      "baseline_psych; Integer\n",
      "baseline_pulmonary; Integer\n",
      "ahrq_ccs; Integer\n",
      "ccsComplicationRate; Double\n",
      "ccsMort30Rate; Double\n",
      "complication_rsi; Double\n",
      "dow; Integer\n",
      "gender; Integer\n",
      "hour; Integer\n",
      "month; Integer\n",
      "moonphase; Integer\n",
      "mort30; Integer\n",
      "mortality_rsi; Double\n",
      "race; Integer\n",
      "complication; Integer\n"
     ]
    }
   ],
   "source": [
    "int size = Data.columnCount(); //sets size = # of columns\n",
    "\n",
    "String[] Name = new String[size]; // Names of the columns\n",
    "String[] Type = new String[size]; // Types of the columns\n",
    "for(int i = 0; i < Name.length; i++){\n",
    "    Name[i] = Data.column(i).toString(); //Getting the info of the column in position i of the array\n",
    "    int startIndex = Name[i].indexOf(\" \"); //first space is after type\n",
    "    Type[i] = Name[i].substring(0, startIndex);\n",
    "    startIndex = Name[i].indexOf(\":\"); //: is after \"type column\"\n",
    "    Name[i] = Name[i].substring(startIndex + 2, Name[i].length()); //start index +2 because there is a space after the :\n",
    "    //removing everything before the column name\n",
    "    System.out.println(Name[i] + \"; \" + Type[i]);\n",
    "}\n",
    "\n",
    "\n",
    "//Combine, consolidate, remove.\n",
    "//Change any binary integer columns (0, 1) to instead be (-1, +1). Including target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"2b6aa494de2448af8c067f1084b6b4fa\"></div>\n",
       "<script>require(['https://cdn.plot.ly/plotly-1.44.4.min.js'], Plotly => {\n",
       "var target_2b6aa494de2448af8c067f1084b6b4fa = document.getElementById('2b6aa494de2448af8c067f1084b6b4fa');\n",
       "var layout = {\n",
       "    title: '% complication by Age',\n",
       "    height: 700,\n",
       "    width: 900,\n",
       "\n",
       "\n",
       "};\n",
       "\r\n",
       "var trace0 =\n",
       "{\n",
       "x: [\"56\",\"37\",\"71\",\"90\",\"22\",\"62\",\"68\",\"31\",\"45\",\"54\",\"59\",\"67\",\"44\",\"63\",\"66\",\"41\",\"53\",\"28\",\"49\",\"64\"],\n",
       "y: [0.12343750000000013, 0.10335195530726267, 0.16062683643486766, 0.9402985074626866, 1.0, 0.5007496251874048, 0.7924528301886791, 0.8500000000000002, 0.4724919093851137, 0.1911764705882351, 0.4135338345864657, 0.7398373983739843, 0.4339622641509436, 0.5668016194331975, 0.7111111111111119, 0.2638580931263857, 0.3395348837209306, 0.8823529411764706, 0.37142857142857155, 0.664285714285714],\n",
       "orientation: 'v',\n",
       "xaxis: 'x',\n",
       "yaxis: 'y',\n",
       "type: 'bar',\n",
       "name: '',\n",
       "};\r\n",
       "\r\n",
       "\n",
       "var data = [ trace0];\r\n",
       "Plotly.newPlot(target_2b6aa494de2448af8c067f1084b6b4fa, data, layout);\n",
       "})</script>\n"
      ],
      "text/plain": [
       "tech.tablesaw.plotly.components.Figure@1046018e"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double threshold = 0.025; //% considered to be statistically similar to another source\n",
    "//Too high will result in every column being removed, too low will result in no changes to the dataset.\n",
    "Table NewData = Data.copy(); //creating a new table which we will make the modifications on.\n",
    "\n",
    "\n",
    "\n",
    "//This for loop will go through the dataset and automatically prune the data for us. Based on the double value \n",
    "//given above, it will combine numbers which are close enough together, and remove columns which do not add \n",
    "//significant information for the target.\n",
    "for(int i = 0; i < Name.length - 1; i++){ //requires target to be last attribute (it is in our case)\n",
    "    if(Type[i].charAt(0) == 'I'){ //first character is only I if it's an integer type column.\n",
    "        Table tempTable = Data.summarize(\"complication\", mean).by(Name[i]); //shows % target for each value\n",
    "        int rows = tempTable.rowCount();\n",
    "        double[] percentTarget = new double[rows];\n",
    "        int[] condition = new int[rows];\n",
    "        for(int j = 0; j < rows; j++){ //filling arrays with values from the created table\n",
    "            percentTarget[j] = tempTable.doubleColumn(1).get(j); //set array equal to percent values\n",
    "            condition[j] = tempTable.intColumn(0).get(j); //set array equal to the int values\n",
    "        }\n",
    "        double tempD = 0; //temp double for rearranging array\n",
    "        int tempI = 0; //temp int for rearranging array\n",
    "        for(int j = 0; j < rows-1; j++){ //sorting arrays based on target %. Slow, but sorts both arrays based on one.\n",
    "            for(int k = j+1; k < rows; k++){ //This is just bubble sort, could be improved in the future.\n",
    "                if(percentTarget[j] > percentTarget[k]){ //sorts smallest to largest\n",
    "                    tempD = percentTarget[j];\n",
    "                    tempI = condition[j];\n",
    "                    percentTarget[j] = percentTarget[k];\n",
    "                    condition[j] = condition[k];\n",
    "                    percentTarget[k] = tempD;\n",
    "                    condition[k] = tempI;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        for(int j = rows-1; j > 0; j--){ //replacing original column values if it's within closeness threshold\n",
    "            tempD = percentTarget[j] - threshold;\n",
    "            for(int k = j-1; k >= 0; k--){\n",
    "                if(tempD < percentTarget[k] && condition[k] != condition[j]){ //also break if conditions are equal\n",
    "                    // they should only be equal if the row was considered similar to a previous row. \n",
    "                    \n",
    "                    NewData.intColumn(i).set(NewData.intColumn(i).isEqualTo(condition[k]), condition[j]);\n",
    "                    //replace column values\n",
    "                    condition[k] = condition[j];\n",
    "                    percentTarget[k] = percentTarget[j]; //changes probability to that in j. Prevents a case where\n",
    "                    //the entire column gradually changes slowly enough to where every number would be considered\n",
    "                    //similar to eachother. In that same case there would instead be much more values in the column.\n",
    "                }\n",
    "                else //if tempD is bigger break, since the array is sorted nothing else can be similar\n",
    "                    break;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    else{//else always catches double columns.\n",
    "    Table tempTable = NewData.summarize(Name[i], mean).by(\"complication\"); //shows average value for 0 and 1 on target\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "//Lets take a look at what this did to our age graph.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "String condition = \"Age\"; //using string as what we're testing against the complication data\n",
    "//The input string must point to an integer type column.\n",
    "\n",
    "Table complications3 = NewData.summarize(target, mean).by(condition); //table of complication and condition\n",
    "\n",
    "VerticalBarPlot.create(\"% \" + target + \" by \" + condition, //plot title\n",
    "    complications3,         //table\n",
    "    condition,              //grouping column name\n",
    "    \"mean [\" + target + \"]\"); //numeric column name\n",
    "\n",
    "\n",
    "//Now only 20 groups remain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further changes\n",
    "\n",
    "\n",
    "\n",
    "Now that we've removed some numbers from the original data, we need to do one final change to the remaining numbers. Integer columns which contain only two digits should be changed to -1 and +1, and integer columns with more should be placed in order from highest to lowest %, then put half as negative values and half as positive values. Integer columns with only 1 value should be outright removed.\n",
    "\n",
    "We will make no changes for double columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       Structure of Surgical-deepnet.csv       \r\n",
       " Index  |     Column Name     |  Column Type  |\r\n",
       "-----------------------------------------------\r\n",
       "     0  |                bmi  |      INTEGER  |\r\n",
       "     1  |                Age  |      INTEGER  |\r\n",
       "     2  |         asa_status  |      INTEGER  |\r\n",
       "     3  |    baseline_cancer  |      INTEGER  |\r\n",
       "     4  |  baseline_charlson  |      INTEGER  |\r\n",
       "     5  |  baseline_dementia  |      INTEGER  |\r\n",
       "     6  |  baseline_diabetes  |      INTEGER  |\r\n",
       "     7  |  baseline_osteoart  |      INTEGER  |\r\n",
       "     8  |     baseline_psych  |      INTEGER  |\r\n",
       "     9  |           ahrq_ccs  |      INTEGER  |\r\n",
       "   ...  |                ...  |          ...  |\r\n",
       "    12  |   complication_rsi  |       DOUBLE  |\r\n",
       "    13  |                dow  |      INTEGER  |\r\n",
       "    14  |             gender  |      INTEGER  |\r\n",
       "    15  |               hour  |      INTEGER  |\r\n",
       "    16  |              month  |      INTEGER  |\r\n",
       "    17  |          moonphase  |      INTEGER  |\r\n",
       "    18  |             mort30  |      INTEGER  |\r\n",
       "    19  |      mortality_rsi  |       DOUBLE  |\r\n",
       "    20  |               race  |      INTEGER  |\r\n",
       "    21  |       complication  |      INTEGER  |"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Table Modified = NewData.copy();\n",
    "\n",
    "for(int i = Name.length - 1; i >= 0; i--){ //Starting at the end because columns are going to be removed.\n",
    "    if(Type[i].charAt(0) == 'I'){ //first character is only I if it's an integer type column.\n",
    "        Table tempTable = NewData.summarize(\"complication\", mean).by(Name[i]); //shows % target for each value\n",
    "        int rows = tempTable.rowCount(); //if there is only 1 row, the attribute is not significant. Drop the column.\n",
    "        if(rows == 1){\n",
    "            Modified.removeColumns(i);\n",
    "        }\n",
    "        else if(rows == 2){//no need to sort again if there are only two rows.\n",
    "            int store1 = tempTable.intColumn(0).get(0); //one of two values in the column\n",
    "            int store2 = tempTable.intColumn(0).get(1); //one of two values in the column\n",
    "            \n",
    "            if(store1 == -1 || store2 == -1){//if either value is already -1\n",
    "                if(store1 == -1){ //store1 is already -1\n",
    "                    Modified.intColumn(i).set(Modified.intColumn(i).isEqualTo(store2), 1);\n",
    "                }\n",
    "                else{ //store2 is already -1\n",
    "                    Modified.intColumn(i).set(Modified.intColumn(i).isEqualTo(store1), 1);\n",
    "                }\n",
    "            }\n",
    "            else{ //if neither value is -1 already\n",
    "                Modified.intColumn(i).set(Modified.intColumn(i).isEqualTo(store1), -1);\n",
    "                Modified.intColumn(i).set(Modified.intColumn(i).isEqualTo(store2), 1);\n",
    "            }\n",
    "        }\n",
    "        else{ //3 or more values in the column\n",
    "            double[] percentTarget = new double[rows];\n",
    "            int[] condition = new int[rows];\n",
    "            for(int j = 0; j < rows; j++){ //filling arrays with values from the created table\n",
    "                percentTarget[j] = tempTable.doubleColumn(1).get(j); //set array equal to percent values\n",
    "                condition[j] = tempTable.intColumn(0).get(j); //set array equal to the int values\n",
    "            }//arrays now have \n",
    "            double tempD = 0; //temp double for rearranging array\n",
    "            int tempI = 0; //temp int for rearranging array\n",
    "            for(int j = 0; j < rows-1; j++){ //sorting arrays based on target %. Slow, but sorts both arrays based on one.\n",
    "                for(int k = j+1; k < rows; k++){ //This is just bubble sort, could be improved in the future.\n",
    "                    if(percentTarget[j] > percentTarget[k]){ //sorts smallest to largest\n",
    "                        tempD = percentTarget[j];\n",
    "                        tempI = condition[j];\n",
    "                        percentTarget[j] = percentTarget[k];\n",
    "                        condition[j] = condition[k];\n",
    "                        percentTarget[k] = tempD;\n",
    "                        condition[k] = tempI;\n",
    "                    }//The data is now sorted from lowest to highest %, attribute values are jumbled.\n",
    "                }\n",
    "            }//only columns with 3 or more remaining attributes arrive here.\n",
    "            int half = rows / 2; //integer division, rounds down\n",
    "            boolean crossover = false; //if there is crossover in the allocation set to 1.\n",
    "            int largest = 0; //will be the index of the largest number if needed.\n",
    "            int count = 0; //count how many unique negatives there are in the column\n",
    "            int[] newAllocation = new int[rows]; //new allocation value for the attributes\n",
    "            int[] crossoverList = new int[rows]; //will hold the index of the crossover cases\n",
    "            \n",
    "            for(int j = 0; j < rows; j++){ //new allocations will be approximately evently distrubuted across\n",
    "                //the negative. 0 is not a taken value.\n",
    "                if(j < half){\n",
    "                    newAllocation[j] = j - half;\n",
    "                }\n",
    "                else{ //+1 so we skip 0 being taken\n",
    "                    newAllocation[j] = j - half + 1;\n",
    "                }\n",
    "            }\n",
    "            for(int j = 0; j < rows; j++){\n",
    "                for(int k = 0; k < rows; k++){\n",
    "                    if(condition[j] == newAllocation[k]){\n",
    "                        crossover = true;\n",
    "                        crossoverList[j] = 1;\n",
    "                        break;\n",
    "                    }\n",
    "                }\n",
    "                if(condition[j] > condition[largest]){\n",
    "                    largest = j; //largest holds the index for the largest number\n",
    "                }\n",
    "            }\n",
    "            largest = condition[largest]; //make largest hold the largest value\n",
    "            \n",
    "            if(crossover){ //if some new allocations are already filled change the value in the column\n",
    "                //and in the array\n",
    "                for(int j = 0; j < rows; j++){\n",
    "                    if(crossoverList[j] == 1){\n",
    "                        largest++; //increment largest so we can use it\n",
    "                        Modified.intColumn(i).set(Modified.intColumn(i).isEqualTo(condition[j]), largest);\n",
    "                        condition[j] = largest;\n",
    "                        crossoverList[j] = 0;\n",
    "                        //replacing crossover with new large value. This is temporary.\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            //if no new allocations are already filled. Should be no crossover left, if there was any.\n",
    "            for(int j = 0; j < rows; j++){\n",
    "                Modified.intColumn(i).set(Modified.intColumn(i).isEqualTo(condition[j]), newAllocation[j]);\n",
    "                //set the values to their new allocations.\n",
    "            }\n",
    "        }//end of 3 or more values if statement\n",
    "    }\n",
    "    else{//else always catches double columns. We won't modify these at all, the below instruction runs, but does not\n",
    "        //modify the table at all. \n",
    "        Table tempTable = Modified.summarize(Name[i], mean).by(\"complication\"); //shows average value for 0 and 1 on target\n",
    "    }\n",
    "}\n",
    "Modified.structure(); //A look at the new "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9386 rows X 22 cols"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Split the data into train and test sets. \n",
    "\n",
    "\n",
    "Table[] splits = Modified.sampleSplit(.8); //splits the NewData into an 80/20 split\n",
    "Table train = splits[0]; //takes the 80% split\n",
    "Table test = splits[1];  //takes the 20% split\n",
    "train.shape();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0: 40.0; W1: 25.0; W2: -1.0; W3: -7.0; W4: -6.0; W5: -3.0; W6: -3.0; W7: -7.0; W8: -7.0; \n",
      "W9: 10.0; W10: 0.33889034000000007; W11: -0.00841289; W12: 2.4299999999999997; W13: 8.0; W14: -1.0; W15: -5.0; W16: 9.0; \n",
      "W17: -7.0; W18: -3.0; W19: 5.0200000000000005; W20: -3.0; W21: 3.0; \n",
      "With 1256 errors.\n",
      "13.381632218197314% Error\n"
     ]
    }
   ],
   "source": [
    "//Pocket algorithm\n",
    "\n",
    "double[] weight = new double[train.columnCount()]; //weights for attributes + 1 for bias\n",
    "double[] bestWeight = new double[train.columnCount()]; //weights for attributes + 1 for bias\n",
    "int inError = 0; //in error \n",
    "int bestInError = 99999999; //best in error. initialized high so it's instantly replaced.\n",
    "int itterations = 0;\n",
    "int randError = 0; //will hold the row which will help us learn for weights\n",
    "double check = 0;\n",
    "int trainSize = train.rowCount(); //how many rows are in the training set\n",
    "int[] errorArray = new int[trainSize]; //tracks what rows have had errors.\n",
    "int attrLoop = train.columnCount() - 1;\n",
    "double target = 0;\n",
    "\n",
    "//The following variables can be changed at will\n",
    "int loopThreshold = 1500; //number of loops we'll do maximum.\n",
    "int threshold = 1000; //exit if less than this many errors\n",
    "//should be at least smaller than the number of rows you have in your dataset or it does nothing\n",
    "double bias = 1; //set bais to 1\n",
    "\n",
    "\n",
    "while(true){ //goes forever, only exits from break;\n",
    "    for(int i = 0; i < trainSize; i++){\n",
    "        check = 0;\n",
    "        for(int j = 0; j < attrLoop; j++){ //-1 so we don't do the target as well.\n",
    "            if(j == attrLoop - 1){\n",
    "                check += weight[j] * bias;\n",
    "            }\n",
    "            else{\n",
    "                target = Double.parseDouble(train.get(i, j).toString());\n",
    "                check += weight[j] * target;\n",
    "            }\n",
    "        }\n",
    "        target = Double.parseDouble(train.get(i, train.columnCount() - 1).toString());\n",
    "        //target is the value of the target for that row\n",
    "        if(check >= 0 && (int) target == -1){ //calculated target != target\n",
    "            inError += 1;\n",
    "            errorArray[i] = 1;\n",
    "        }\n",
    "        else if(check < 0 && (int) target == 1){//calculated target != target\n",
    "            inError += 1;\n",
    "            errorArray[i] = 1;\n",
    "        }\n",
    "    }\n",
    "    if(inError < bestInError){ //if we have a new best in sample error update best weights and best inError\n",
    "        for(int i = 0; i < weight.length; i++){\n",
    "            bestWeight[i] = weight[i]; //update best weights\n",
    "        }\n",
    "        bestInError = inError;\n",
    "    }\n",
    "    if(bestInError < threshold){ //if we're happy with the error, break from the loop.\n",
    "        break;\n",
    "    }\n",
    "    else if(itterations >= loopThreshold){ //break if we do too many itterations\n",
    "        break;\n",
    "    }\n",
    "    else{ //if we're continuing the loop, update the weights.\n",
    "        while(true){\n",
    "            Random rand = new Random();\n",
    "            randError = rand.nextInt(trainSize);\n",
    "            if(errorArray[randError] == 1) //choosing a random error which modifies weights.\n",
    "                break;\n",
    "        }\n",
    "        //System.out.println(randError + \" \" + itterations + \" \" + inError);\n",
    "        for(int i = 0; i < weight.length; i++){\n",
    "            if(i < weight.length - 1){\n",
    "                weight[i] = bestWeight[i] + (Double.parseDouble(train.get(randError, i).toString()) \n",
    "                                         * Double.parseDouble(train.get(randError, train.columnCount() - 1).toString()));\n",
    "            }\n",
    "            else{\n",
    "                weight[i] = bestWeight[i] + (bias \n",
    "                                        * Double.parseDouble(train.get(randError, train.columnCount() - 1).toString()));\n",
    "            }\n",
    "                \n",
    "        }\n",
    "        inError = 0;\n",
    "    }\n",
    "    itterations += 1;\n",
    "}\n",
    "\n",
    "\n",
    "for(int i = 0; i < weight.length; i++){\n",
    "    System.out.print(\"W\" + i + \": \" + bestWeight[i] + \"; \"); //bias weight is the final weight\n",
    "    if(i % 8 == 0 && i != 0)\n",
    "        System.out.print(\"\\n\"); //makes the output more readable\n",
    "}\n",
    "System.out.println(\"\\nWith \" + bestInError + \" errors.\");\n",
    "System.out.println((((double)bestInError / (double)trainSize) * 100) + \"% Error\"); //gives % in error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out of sample error\n",
    "\n",
    "\n",
    "We used the pokket algorithm to get some weights, and the in sample error seems pretty good. Now that we have our final weights, we need to calculate our out of sample error. Our in sample error will be different each time we run the program, because we randomly select the row which changes the weights, and the train/test sets are also randomly calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2347 rows X 22 cols"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 291 Errors.\n",
      "There were 32 false positives, and 259 false negatives.\n",
      "The out of sample error is: 12.398806987643802%\n"
     ]
    }
   ],
   "source": [
    "//finding the out of sample error\n",
    "\n",
    "int testSize = test.rowCount(); //rows in test set\n",
    "int testAttr = test.columnCount() - 1; //columns in test set (will be the same as those in train set)\n",
    "double testCheck = 0; //sum weights * attribtues\n",
    "double testTarget = 0; //holds target value.\n",
    "int Eout = 0; //out of sample error\n",
    "int falsePositive = 0; //count false positives\n",
    "int falseNegative = 0; //count false negatives\n",
    "\n",
    "\n",
    "for(int i = 0; i < testSize; i++){\n",
    "    testCheck = 0;\n",
    "    for(int j = 0; j < testAttr - 1; j++){ //-1 so we don't do the target as well.\n",
    "        if(j == testAttr - 1){\n",
    "            testCheck += bestWeight[j] * bias;\n",
    "        }\n",
    "        else{\n",
    "            testTarget = Double.parseDouble(test.get(i, j).toString()); //holds attribute value for readability.\n",
    "            testCheck += bestWeight[j] * testTarget;\n",
    "            testTarget = 0;\n",
    "        }\n",
    "    }\n",
    "    testTarget = Double.parseDouble(test.get(i, test.columnCount() - 1).toString());\n",
    "    //target is the value of the target for that row\n",
    "    if(testCheck >= 0 && testTarget == -1){ //calculated target sign != target sign\n",
    "        Eout++;\n",
    "        falsePositive++;\n",
    "    }\n",
    "    else if(testCheck < 0 && testTarget == 1){//calculated target sign != target sign\n",
    "        Eout++;\n",
    "        falseNegative++;\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "System.out.println(\"There were \" + Eout + \" Errors.\");\n",
    "System.out.println(\"There were \" + falsePositive + \" false positives, and \" + falseNegative + \" false negatives.\");\n",
    "System.out.println(\"The out of sample error is: \" + ((double) Eout / (double)testSize) * 100 + \"%\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good out of sample error\n",
    "\n",
    "\n",
    "It looks like we got some good weights. Our out of sample error is very close to our in sample error. We could try some other algorithms as well if we wanted to, but as long as future data is formatted the same way we formatted this data, we'll have developed a good precdictor with the current weights.\n",
    "\n",
    "We can see which attributes are most important by comparing the magnitude of the weights, heavier weights imply more important attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bmi; 40.0\n",
      "Age; 25.0\n",
      "asa_status; -1.0\n",
      "baseline_cancer; -7.0\n",
      "baseline_charlson; -6.0\n",
      "baseline_dementia; -3.0\n",
      "baseline_diabetes; -3.0\n",
      "baseline_osteoart; -7.0\n",
      "baseline_psych; -7.0\n",
      "ahrq_ccs; 10.0\n",
      "ccsComplicationRate; 0.33889034000000007\n",
      "ccsMort30Rate; -0.00841289\n",
      "complication_rsi; 2.4299999999999997\n",
      "dow; 8.0\n",
      "gender; -1.0\n",
      "hour; -5.0\n",
      "month; 9.0\n",
      "moonphase; -7.0\n",
      "mort30; -3.0\n",
      "mortality_rsi; 5.0200000000000005\n",
      "race; -3.0\n",
      "complication; 3.0\n"
     ]
    }
   ],
   "source": [
    "int finalSize = Modified.columnCount(); //sets finalSize = # of columns\n",
    "\n",
    "String[] columnNames = new String[finalSize]; // Names of the columns\n",
    "int startIndex = 0;\n",
    "\n",
    "\n",
    "for(int i = 0; i < columnNames.length; i++){\n",
    "    columnNames[i] = Modified.column(i).toString(); //Getting the info of the column in position i of the array\n",
    "    startIndex = columnNames[i].indexOf(\":\"); //: is after \"type column\"\n",
    "    columnNames[i] = columnNames[i].substring(startIndex + 2, columnNames[i].length()); //start index +2 because there is a space after the :\n",
    "    //removing everything before the column name\n",
    "    System.out.println(columnNames[i] + \"; \" + bestWeight[i]);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Closing remarks\n",
    "\n",
    "\n",
    "We were able to create a pretty good set of weights for the given dataset. We started off looking at how the data was formatted, and converted a few double columns into int columns. We proceeded to see graphs of the data, allowing us to easily look at any given attribute in relation to the target. Finally, we combined data which hit the target function a similar amount of times, and completely removed columns which only had 1 value after the combination. Finally, we gave the columns completely new data, ordering it in terms of probability to have the target function be a 1, and then put half in the negative class and half positive. After completing data manipulation, we ran the data against pocket algorithm to find weights, and calculated our final Ein and Eout.\n",
    "\n",
    "We can also see which attributes impact the prediction the most by observing the magnitude of the weights."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "12.0.2+10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
